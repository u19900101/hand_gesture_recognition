{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 制作数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "videodir = 'D:/py/My_work/video/'\n",
    "dirlist = os.listdir(videodir)\n",
    "category = np.arange(6).tolist()\n",
    "C = [[] for i in range(6)]\n",
    "for i in dirlist:\n",
    "    strtemp = i.split('-')[0]\n",
    "    M = int(strtemp) if strtemp.isdigit() else strtemp\n",
    "    if M in category:\n",
    "        C[category.index(M)].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采集右半屏区域 去除背景后的手势\n",
    "import cv2\n",
    "\n",
    "def cutimg(imgpath,dirname,videoname,tot = 0):\n",
    "    # 开启电脑上摄像头进行实时预测\n",
    "    cap = cv2.VideoCapture(imgpath)\n",
    "    # 循环使用cv2的read()方法读取视频帧\n",
    "    while 1:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "            filename = dirname +'/'+videoname.split('.')[0]+'_'+ str(tot) + '.jpg'\n",
    "            filename1 = dirname +'/'+videoname.split('.')[0]+'_flip_'+ str(tot) + '.jpg'\n",
    "          # img = bs.apply(frame)\n",
    "            cap_region_x_begin = 0.5  # start point/total width\n",
    "            cap_region_y_end = 1  # start point/total width\n",
    "\n",
    "            img = img[0:int(cap_region_y_end * img.shape[0]),\n",
    "                  0:int(cap_region_x_begin * img.shape[1])]  # clip the ROI\n",
    "            img1 = cv2.flip(img, 1)  # flip the frame horizontally\n",
    "            if  tot<50:\n",
    "                filename = dir+'-1/'+videoname.split('.')[0]+'_'+ str(tot) + '.jpg'\n",
    "                filename1 =  dir+'-1/'+videoname.split('.')[0]+'_flip_'+ str(tot) + '.jpg'\n",
    "            cv2.imwrite(filename, img)\n",
    "            cv2.imwrite(filename1, img1)\n",
    "                # cv2.imshow('frame2', img)\n",
    "            if tot%50 ==0:\n",
    "                print('tot=',tot, filename)\n",
    "            # break\n",
    "            tot += 1\n",
    "        \n",
    "            k = cv2.waitKey(1) & 0xff\n",
    "            if k == 27:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "       \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "#     return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'dataset2/'\n",
    "for i in C:\n",
    "    count = 0\n",
    "    cla = i[0].split('-')[0]\n",
    "    # print(i)\n",
    "    dirname = dir+cla\n",
    "    os.makedirs(dirname,exist_ok = True)\n",
    "    for j in i:\n",
    "        # print(videodir+j)\n",
    "        # imgpath = 'D:/py/My_work/video/3-2.mp4'   \n",
    "        print(\"进入视频{}采集\".format(j))\n",
    "        cutimg(videodir+j,dirname,j)\n",
    "#         print(\"count now is \",count)\n",
    "    print(\"类别{}采集完毕\".format(cla))\n",
    "    # strtemp = i.split('-')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "np.random.seed(42)\n",
    "path = pathlib.Path('dataset2')\n",
    "data = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.4,\n",
    "        ds_tfms=get_transforms(), size=128, num_workers=0).normalize(imagenet_stats)# size的设置不超过224，不然内存不够\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "learn = cnn_learner(data, models.resnet34, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看分类 、训练集 、 验证集的数量\n",
    "data.classes, data.c, len(data.train_ds), len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后我们运行学习率查找方法，把它的结果画出来（它会告诉你输入什么代码来画出结果）。我们看下这个图。\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=slice(1e-3,1e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我喜欢把开始的结果保存下来，res34 size224\n",
    "name = '../../model/10-times-res34-0137'\n",
    "learn.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#像以前一样，我们可以使用ClassificationInterpretation类型来看看结果。\n",
    "learn.load(name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先将模型导出：\n",
    "#这会在目录中创建一个名为export.pkl的文件，它包含了部署模型所需要的所有内容（模型，权重以及一些元数据）\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export.pkl，然后我们在生产环境中创建学习器：\n",
    "\n",
    "learn = load_learner(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对已命名的数字文件夹进行预测，并显示准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from fastai.vision import *\n",
    "from collections import Counter\n",
    "path = pathlib.Path('dataset2')\n",
    "def backgroudRemove(imgpath):\n",
    "    # 加载本地视频进行预测\n",
    "    cap = cv2.VideoCapture(imgpath)\n",
    "    # 开启电脑上摄像头进行实时预测\n",
    "#     cap = cv2.VideoCapture(0)\n",
    "    bs = cv2.createBackgroundSubtractorKNN(detectShadows=True)\n",
    "    tot = 1\n",
    "    # 读取训练的模型进行预测\n",
    "    learn = load_learner(path)\n",
    "    #设置起始预测值为 -1\n",
    "    preNum = -1\n",
    "    count = 0\n",
    "    num = (imgpath.split('/')[-1]).split('-')[0]\n",
    "    num = num if num.isdigit() else -1\n",
    "    Res = [-1 for i in range(8)]\n",
    "    # 循环使用cv2的read()方法读取视频帧\n",
    "    while 1:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "         \n",
    "#             frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "          \n",
    "#             img = bs.apply(frame)\n",
    "            \n",
    "      \n",
    "            cap_region_x_begin = 0.5  # start point/total width\n",
    "            cap_region_y_end = 1  # start point/total width\n",
    "\n",
    "            img = img[0:int(cap_region_y_end * img.shape[0]),\n",
    "                  0:int(cap_region_x_begin * img.shape[1])]  # clip the ROI\n",
    "            img = cv2.flip(img, 1)  # flip the frame horizontally\n",
    "#             cv2.imshow('frame1', img)\n",
    "#             cv2.imwrite('temp.jpg', img)\n",
    "\n",
    "            img_fastai = Image(pil2tensor(img, dtype=np.float32).div_(255)) #已进行归一化处理\n",
    "            pred_class, pred_idx, outputs = learn.predict( img_fastai)\n",
    "            \n",
    "            # 将预测结果保存下来进行查看或者作为数据集添加数据\n",
    "            # cv2.imwrite('D:/py/10.0-2.13-opencv/jupyter-notebook/work1_hand_reg/img_cut/' +str(a)+'_'+ str(tot) + '.jpg', img)\n",
    "            \n",
    "            Res.pop(0)\n",
    "            Res.append(int(str(pred_class)))\n",
    "            res = Counter(Res).most_common(1)[0][0]\n",
    "            cv2.putText(img,str(res), (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 255, 255), 10, cv2.LINE_AA)\n",
    "#             cv2.putText(img,str(pred_class), (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 255, 255), 10, cv2.LINE_AA)\n",
    "            cv2.imshow('frame2', img)\n",
    "            \n",
    "#             res = 0\n",
    "#             if int(res)!=int(num) and tot>72:\n",
    "#                 count +=1\n",
    "#                 if  count%10==0:\n",
    "#                     print(\"预测错误，序号为：{}，真实值为 {}, 预测值为：{},预测错误累计次数为：{}\".format(tot-72,num,preNum,count))\n",
    "    \n",
    "            k = cv2.waitKey(1) & 0xff\n",
    "            if k == 27:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "        tot += 1\n",
    "#     print(\"错误率为{:.4f} %,预测数量为 {}，错误数量为：{}\".format(count/(tot-72)*100,tot-72,count))\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return imgpath+\"错误率为 ： \"+str(count/(tot-50))\n",
    "\n",
    "dir = 'D:/py/My_work/video/'\n",
    "# dirlist = os.listdir(dir)\n",
    "dirlist = 'demo2.mp4'\n",
    "res = []\n",
    "backgroudRemove(dir + dirlist)\n",
    "# for videopath in dirlist:\n",
    "#     print(dir + videopath)\n",
    "#     r = backgroudRemove(dir + videopath)\n",
    "#     res.append(r)\n",
    "\n",
    "#3-1  3-2  4-1 4-2 5-1 错误率高于20%    采用24个连续的预测均值后错误率下降到10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用百度API进行预测，速度太慢，达不到实时的要求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding:utf-8\n",
    "import requests \n",
    "\n",
    "# client_id 为官网获取的AK， client_secret 为官网获取的SK\n",
    "host = 'https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id=Q1rsKyaEdy4T6gW0MpsAGza3&client_secret=NuXBpF0W5XTvX4aNO0E4juZfacFG5qwX'\n",
    "response = requests.get(host)\n",
    "if response:\n",
    "    print(response.json()[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "def filename(imgpath):\n",
    "    request_url = \"https://aip.baidubce.com/rest/2.0/image-classify/v1/gesture\"\n",
    "    # 二进制方式打开图片文件\n",
    "    f = open(imgpath, 'rb')\n",
    "    img = base64.b64encode(f.read())\n",
    "\n",
    "    params = {\"image\":img}\n",
    "    access_token = '24.6bd8a1f2fbe078f228c130868f8c2f5f.2592000.1591627146.282335-19801644'\n",
    "    request_url = request_url + \"?access_token=\" + access_token\n",
    "    headers = {'content-type': 'application/x-www-form-urlencoded'}\n",
    "    response = requests.post(request_url, data=params, headers=headers)\n",
    "    if response:\n",
    "        classname = response.json()['result'][0]['classname']\n",
    "        probability = response.json()['result'][0]['probability']\n",
    "        print (classname,probability)\n",
    "        return classname,probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename('imgforBaidu/293.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 断点续训"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint the weights when validation accuracy improves\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed= 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset= numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X= dataset[:,0:8]\n",
    "Y= dataset[:,8]\n",
    "# create model\n",
    "model= Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "weightpath = \"./checkpoint/weights-best.hdf5\"\n",
    "if os.path.exists(weightpath):\n",
    "    model.load_weights(filepath)\n",
    "    # 若成功加载前面保存的参数，输出下列信息\n",
    "    print(\"checkpoint_loaded\")\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# checkpoint\n",
    "filepath=\"./checkpoint/weights-best.hdf5\"\n",
    "checkpoint= ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list= [checkpoint]\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.33, epochs=15, batch_size=10, callbacks=callbacks_list, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python36564bitb7cea9d7ef004cdbb465f212868e7b56"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}